{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OsuLearn\n",
    "## An attempt at creating a Neural Network that learns how to play osu!std like a human from replays\n",
    "\n",
    "##### (Plz don't judge me too much I'm new to machine learning and I can't english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dniid/osu-learn/blob/colab/osulearn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!git clone https://github.com/dniid/osu-learn\n",
    "!mv osu-learn/* ./\n",
    "!rm -rf osu-learn* sample_data\n",
    "!git checkout colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "from importlib import reload\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from osrparse import Replay\n",
    "\n",
    "import osu.rulesets.beatmap\n",
    "import osu.rulesets.hitobjects as hitobjects\n",
    "import osulearn.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## osu!\n",
    "\n",
    "> osu! is a free and open-source rhythm game developed and published by Australian-based company PPY Developments PTY, created by Dean Herbert (also known as peppy). Originally released for Microsoft Windows on September 16, 2007, the game has also been ported to macOS (this version might be unstable), and Windows Phone. Its gameplay is based on titles including Osu! Tatakae! Ouendan, Elite Beat Agents, Taiko no Tatsujin, Beatmania IIDX, O2Jam, and DJMax. \n",
    ">\n",
    "> -- <cite>[Wikipedia](https://en.wikipedia.org/wiki/Osu!)</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This project aims to create a Neural Network that is capable of learning how to play osu! as humanly as possible.\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "To accomplish that, I'll be applying [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) by feeding a [Recurrent Neural Network](https://en.wikipedia.org/wiki/Recurrent_neural_network) with beatmap data as input, training it to reproduce replay data from my recorded plays. These will be read from my Replay and Songs directories at my osu! installation respectively.\n",
    "\n",
    "In the future, it would be interesting to try and implement a Conditional [Generative Adversarial Network (GAN)](https://en.wikipedia.org/wiki/Generative_adversarial_network) model that receives beatmap data as input and outputs replay data, as this would allow to generate a variety of replays for the same map, which the current model can't do.\n",
    "\n",
    "## The learning data\n",
    "\n",
    "First, all the `.osr` files in the osu! directory are enumerated and put into a table mapping replay file names to the `.osu` file for the replay's beatmap.\n",
    "\n",
    "This is quite expensive to do every time, so a cache file is stored in the `.data/` folder in OsuLearn root dir to reduce overhead. Also, the code is huge and not very enlightening (it's basically a bunch of `glob`s), so it's been moved to `osulearn/dataset.py` to avoid cluttering this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drive.mount('/content/gdrive')\n",
    "OSU_FOLDER = os.path.join(\"/content/gdrive/MyDrive/OsuLearn\")\n",
    "\n",
    "if not os.path.exists(OSU_FOLDER):\n",
    "  os.makedirs(OSU_FOLDER)\n",
    "\n",
    "if not os.path.exists(os.path.join(OSU_FOLDER, '.data')):\n",
    "  os.makedirs(os.path.join(OSU_FOLDER, '.data'))\n",
    "\n",
    "if not os.path.exists(os.path.join(OSU_FOLDER, 'model')):\n",
    "  os.makedirs(os.path.join(OSU_FOLDER, 'model'))\n",
    "\n",
    "if not os.path.exists(os.path.join(OSU_FOLDER, 'generated')):\n",
    "  os.makedirs(os.path.join(OSU_FOLDER, 'generated'))\n",
    "\n",
    "if not os.path.exists(os.path.join(OSU_FOLDER, 'Replays')):\n",
    "  os.makedirs(os.path.join(OSU_FOLDER, 'Replays'))\n",
    "\n",
    "if not os.path.exists(os.path.join(OSU_FOLDER, 'Songs')):\n",
    "  os.makedirs(os.path.join(OSU_FOLDER, 'Songs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = osulearn.dataset.all_files(OSU_FOLDER, verbose=True)\n",
    "#data_files.applymap(os.path.basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After enumerating the required files, they are mapped into `osu.ruleset` objects so we can extract useful information from them. This is done separately from file enumeration mainly because I like to see the Replay/Beatmap filename table, and it's nice to have a progress bar for each step.\n",
    "\n",
    "Please notice DT and HR are not supported because they change timing and object position respectively, and I'm too lazy atm to take that into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = osulearn.dataset.load(data_files, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `osu.ruleset` objects DataFrame in hands, we can now get the data we are really interested in. This step is very time consuming, mainly because it has to calculate the list of visible objects for each frame on every beatmap. I've applyed some optimizations on that but it's still quite time-consuming.\n",
    "\n",
    "The generated input and target data are stored on files in the `.data/` folder in OsuLearn root dir, and are not updated if the generated files are present. If you have saved a new replay, please delete `.data/input_data.dat` and `.data/target_data.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    input_data = pd.read_pickle(os.path.join(OSU_FOLDER, '.data', 'input_data.dat'))\n",
    "except:\n",
    "    input_data = osulearn.dataset.input_data(dataset, verbose=True)\n",
    "    input_data.to_pickle(os.path.join(OSU_FOLDER, '.data', 'input_data.dat'))\n",
    "\n",
    "X = np.reshape(input_data.values, (-1, osulearn.dataset.BATCH_LENGTH, len(osulearn.dataset.INPUT_FEATURES)))\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    target_data = pd.read_pickle(os.path.join(OSU_FOLDER, '.data', 'target_data.dat'))\n",
    "except:\n",
    "    target_data = osulearn.dataset.target_data(dataset, verbose=True)\n",
    "    target_data.to_pickle(os.path.join(OSU_FOLDER, '.data', 'target_data.dat'))\n",
    "\n",
    "y = np.reshape(target_data.values, (-1, osulearn.dataset.BATCH_LENGTH, len(osulearn.dataset.OUTPUT_FEATURES)))\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model\n",
    "\n",
    "The training data is ready, so the next step is to create our model. As I've said at the beginning, I'm new to Machine Learning, so this model is built mostly on top of educated guesses.\n",
    "\n",
    "I think it's reasonable to use a LSTM because replays are time sequences and it's past states are relevant to calculate the next one. Maybe I should use some kind of convolutional layer, but I'm not sure where and how and when I tried to it just made the cursor shake like hell, so maybe not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, GaussianNoise, LSTM\n",
    "\n",
    "\n",
    "map_input = Input(shape=X.shape[1:], name='map_info')\n",
    "\n",
    "lstm = LSTM(64, return_sequences=True)(map_input)\n",
    "pos = Dense(64, activation='linear')(lstm)\n",
    "pos = GaussianNoise(0.2)(pos)\n",
    "pos = Dense(16, activation='linear')(pos)\n",
    "pos = Dense(y.shape[2], activation='linear', name='position')(pos)\n",
    "\n",
    "model = Model(inputs=map_input, outputs=pos)\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='mae')\n",
    "model.summary()\n",
    "\n",
    "try:\n",
    "    model.load_weights(os.path.join(OSU_FOLDER, 'model', 'model.weights.h5'))\n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"Failed to load weights: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training is done by splitting the dataset randomly into training and testing groups and exposing the Neural Network only to the training group. This process is then repeated until the loss is acceptable.\n",
    "\n",
    "From my experience, a good point to stop is at about 0.0600. The number of epochs until this happens may vary depending on the size of the dataset, so feel free to tweak the `ITERATIONS` and `EPOCHS` values as needed to approach this result (or run the next cell until it's done, whatever)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ITERATIONS = 24\n",
    "EPOCHS = 8\n",
    "\n",
    "try:\n",
    "    loss\n",
    "except NameError:\n",
    "    loss = []\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    print(\"Iteration #%d\" % (i + 1))\n",
    "    print(\"_\" * 80)\n",
    "    print()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=randint(0, 100))\n",
    "    h = model.fit(X_train, y_train, batch_size=1024, epochs=EPOCHS, verbose=1)\n",
    "    loss += h.history['loss']\n",
    "    print()\n",
    "\n",
    "model.save_weights(os.path.join(OSU_FOLDER, 'model', 'model.weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats\n",
    "\n",
    "After training it's usually useful to see whether the loss has decreased or how close to the target data the generated data is. For this, we have some `matplotlib` plots right here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def plot_error_colormapped_axis_position(target, predicted, axis):\n",
    "    fig = plt.figure(figsize=(18, 2), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    fig.gca().plot(target[:,axis], color='black', alpha=0.3)\n",
    "    cmap = LinearSegmentedColormap.from_list(\"\", [(0, 0.8, 0), (0.8, 0, 0)])\n",
    "    time = np.linspace(0, len(predicted), len(predicted))\n",
    "    pos = predicted[:,axis]\n",
    "    diff = np.absolute(target[:,axis] - predicted[:,axis])\n",
    "    points = np.array([time, pos]).T.reshape(-1,1,2)\n",
    "    segments = np.concatenate([points[:-2],points[1:-1], points[2:]], axis=1)\n",
    "\n",
    "    norm = plt.Normalize(diff.min(), diff.max())\n",
    "\n",
    "    lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    lc.set_array(diff)\n",
    "    fig.gca().add_collection(lc)\n",
    "    fig.gca().autoscale()\n",
    "    fig.show()\n",
    "\n",
    "def plot_info(target, predicted):\n",
    "    %matplotlib inline\n",
    "\n",
    "    plot_error_colormapped_axis_position(target, predicted, 0)\n",
    "    plt.title(\"X\")\n",
    "    plt.show()\n",
    "\n",
    "    plot_error_colormapped_axis_position(target, predicted, 1)\n",
    "    plt.title(\"Y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_pos = model.predict(X)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Batch\", i)\n",
    "    plot_info(y[i], predicted_pos[i])\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that even when the loss is as low as 0.06 the predictions do not match the target data quite so well. That is not a huge problem though, since we do not really want the IA to match exactly our moves on every replay.\n",
    "\n",
    "The movements between a circle and the next one on osu! are mostly unpredictable, and the best we can do is approximate them. The really important part is that the IA can aim for the circles and move the cursor over them in time.\n",
    "\n",
    "Implementing a GAN would solve most of these problems, as it would not try to generate replays exactly like the target data, but replays that \"look similar\" to them. That will be explored in the future.\n",
    "\n",
    "Finally, let's validate our model and preview a replay it generates for a map it has never seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BEATMAPS_FOLDER = os.path.join(OSU_FOLDER, 'Songs')\n",
    "SONG_ID = '185250'\n",
    "SONG_DIFFICULTY = 'Dreamer'\n",
    "BEATMAP = glob.glob(os.path.join(BEATMAPS_FOLDER, SONG_ID + '*', '*' + SONG_DIFFICULTY + '*.osu'))[0]\n",
    "\n",
    "# Load beatmap data\n",
    "beatmap = osu.rulesets.beatmap.load(BEATMAP)\n",
    "data = osulearn.dataset.input_data(beatmap)\n",
    "data = np.reshape(data.values, (-1, osulearn.dataset.BATCH_LENGTH, len(osulearn.dataset.INPUT_FEATURES)))\n",
    "\n",
    "# Generate AI replay\n",
    "predicted = model.predict(data)\n",
    "\n",
    "# Plot both\n",
    "plot_info(np.concatenate(data), np.concatenate(predicted))\n",
    "\n",
    "# Save\n",
    "beatmap_name = beatmap['Title'] + ' (' + beatmap['Creator'] + ') [' + beatmap['Version'] + ']'\n",
    "replay_data = np.concatenate(predicted)\n",
    "\n",
    "np.save(os.path.join(OSU_FOLDER, 'generated', beatmap_name + '.npy'), replay_data)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preview the generated replay, run this on OsuLearn root directory:\n",
    "```\n",
    "python -m osu.preview\n",
    "```\n",
    "\n",
    "This script needs [`pygame`](https://www.pygame.org/news) and [`mutagen`](https://mutagen.readthedocs.io/en/latest/) to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known Issues\n",
    "\n",
    "Ok, so we've seen the AI can do quite well even on maps it has never been trained to play before, but of course there's some things we can notice it can't do at all:\n",
    "\n",
    "- Spinners: It simply ignores them, haha!\n",
    "- Break time \"random\" movements: during break times the best it can do is just hold the cursor on the center of the screen.\n",
    "\n",
    "What I would guess is happening is that those two actions usually do not have an easily distinguishable pattern to them (spinners are usually \"spinned\", I know, but it's not as precise as aiming or following sliders, since spin direction, speed, radius, etc. varies a lot in a way that is not really predictable). Since we're using a kind of regression technique, it makes sense the model couldn't figure those out.\n",
    "\n",
    "The solution?\n",
    "\n",
    "Use a GAN!!! (╯°□°)╯︵ ┻━┻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
